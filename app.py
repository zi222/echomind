import asyncio
import websockets
import os
import glob
from chat_with_wenwu.streamlit_app import get_qa_history_chain, gen_response, get_available_models
from TTS.tts import text_to_speech, initialize_tts_models
from pathlib import Path

# ç¼“å­˜é—®ç­”é“¾
_qa_chain = None
_selected_model = "qwen2.5-coder-32b-instruct"

def clean_audio_data_folder():
    audio_files = glob.glob("data/*.wav")
    for f in audio_files:
        try:
            os.remove(f)
        except Exception as e:
            print(f"Failed to delete {f}: {e}")

async def send_audio_to_cloud(audio_path):
    uri = "ws://182.92.128.19:8000/ws/upload"
    CHUNK_SIZE = 512 * 1024

    try:
        async with websockets.connect(uri, max_size=50 * 1024 * 1024) as websocket:
            file_size = os.path.getsize(audio_path)
            await websocket.send(f"{os.path.basename(audio_path)},{file_size}")

            with open(audio_path, "rb") as f:
                bytes_sent = 0
                while bytes_sent < file_size:
                    chunk = f.read(CHUNK_SIZE)
                    await websocket.send(chunk)
                    bytes_sent += len(chunk)

        print(f"âœ… éŸ³é¢‘å·²å‘é€è‡³æœåŠ¡å™¨ï¼š{audio_path}")

        # å‘é€æˆåŠŸï¼Œåˆ é™¤éŸ³é¢‘
        os.remove(audio_path)
        print(f"ðŸ—‘ï¸ å·²åˆ é™¤æœ¬åœ°éŸ³é¢‘æ–‡ä»¶ï¼š{audio_path}")

    except Exception as e:
        print(f"âŒ WebSocket å‘é€å¤±è´¥ï¼š{e}ï¼ˆéŸ³é¢‘ä¿ç•™ä»¥ä¾¿é‡è¯•ï¼‰")

def load_qa_chain(model="qwen2.5-coder-32b-instruct", vectordb_path=None):
    global _qa_chain
    _qa_chain = get_qa_history_chain(model=model, vectordb_path=vectordb_path)
    print(f"QA chain loaded with model {model}")

def initialize_models():
    print("åˆå§‹åŒ– TTS æ¨¡åž‹...")
    initialize_tts_models(half=True)
    clean_audio_data_folder()
    load_qa_chain(model=_selected_model)

async def process_text(text):
    # ç”Ÿæˆé—®ç­”ç»“æžœï¼ˆåŒæ­¥è°ƒç”¨ï¼Œè¿™é‡Œå¦‚æžœgen_responseæ”¯æŒå¼‚æ­¥è¯·æ”¹æˆawaitï¼‰
    print(f"æ”¶åˆ°æ–‡æœ¬ï¼Œç”Ÿæˆå›žç­”ï¼š{text}")
    answer = gen_response(
        chain=_qa_chain,
        input=text,
        chat_history=[],
    )
    # å¦‚æžœansweræ˜¯ç”Ÿæˆå™¨ï¼Œåˆå¹¶æˆå­—ç¬¦ä¸²
    if hasattr(answer, '__iter__') and not isinstance(answer, str):
        output = "".join(answer)
    else:
        output = answer

    print(f"ç”Ÿæˆå›žç­”: {output}")

    # åˆæˆè¯­éŸ³ï¼Œè¾“å‡ºè·¯å¾„å›ºå®š
    audio_file_path = "data/audio.mp3"
    # ä½ è¿™é‡Œå¯ä»¥åŠ è‡ªå®šä¹‰éŸ³è‰²åˆ¤æ–­ï¼Œè¿™é‡Œç®€å•ç”¨é»˜è®¤éŸ³è‰²
    prompt_tokens_path = ["/root/codespace/TTS/fake.npy"]

    text_to_speech(output, prompt_tokens_path=prompt_tokens_path, output_audio_path=audio_file_path)
    print(f"è¯­éŸ³åˆæˆå®Œæˆï¼Œè·¯å¾„ï¼š{audio_file_path}")

    # å‘é€éŸ³é¢‘æ–‡ä»¶
    await send_audio_to_cloud(audio_file_path)

async def receive_text_from_pi():
    uri = "ws://182.92.128.19:8000/ws/text"
    async with websockets.connect(uri) as websocket:
        print("è¿žæŽ¥æ ‘èŽ“æ´¾æ–‡å­—è¾“å…¥ WebSocket æˆåŠŸï¼Œç­‰å¾…æ¶ˆæ¯...")
        try:
            while True:
                message = await websocket.recv()
                print(f"æ”¶åˆ°æ ‘èŽ“æ´¾æ¶ˆæ¯: {message}")

                # æ”¶åˆ°æ–‡å­—åŽå¤„ç†ç”Ÿæˆè¯­éŸ³å¹¶å‘é€
                await process_text(message)

        except websockets.exceptions.ConnectionClosed as e:
            print(f"è¿žæŽ¥å…³é—­: {e}")
        except Exception as e:
            print(f"å¼‚å¸¸: {e}")

if __name__ == "__main__":
    initialize_models()
    asyncio.run(receive_text_from_pi())